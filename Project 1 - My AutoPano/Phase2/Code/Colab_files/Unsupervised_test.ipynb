{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsupervised_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "%pip install numpy==1.19.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GirUeA1FLbsL",
        "outputId": "81219405-9420-4ca9-ae83-be5cf1d6e14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "from skimage import data, exposure, img_as_float\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import math as m\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "V9ljC9QuKJWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Aux_M1  = np.array([\n",
        "          [ 0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [ 1 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [ 0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [ 0 , 0 , 1 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [ 0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [ 0 , 0 , 0 , 0  , 1 , 0 , 0 , 0 ],\n",
        "          [ 0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [ 0 , 0 , 0 , 0  , 0 , 0 , 1 , 0 ]], dtype=np.float64)\n",
        "\n",
        "Aux_M2  = np.array([\n",
        "          [ 0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [ 0 , 1 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [ 0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [ 0 , 0 , 0 , 1  , 0 , 0 , 0 , 0 ],\n",
        "          [ 0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [ 0 , 0 , 0 , 0  , 0 , 1 , 0 , 0 ],\n",
        "          [ 0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [ 0 , 0 , 0 , 0  , 0 , 0 , 0 , 1 ]], dtype=np.float64)\n",
        "\n",
        "Aux_M3  = np.array([\n",
        "          [0],\n",
        "          [1],\n",
        "          [0],\n",
        "          [1],\n",
        "          [0],\n",
        "          [1],\n",
        "          [0],\n",
        "          [1]], dtype=np.float64)\n",
        "\n",
        "\n",
        "\n",
        "Aux_M4  = np.array([\n",
        "          [-1 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 ,-1 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  ,-1 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 ,-1 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ]], dtype=np.float64)\n",
        "\n",
        "\n",
        "Aux_M5  = np.array([\n",
        "          [0 ,-1 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 ,-1  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 ,-1 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 ,-1 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ]], dtype=np.float64)\n",
        "\n",
        "Aux_M6  = np.array([\n",
        "          [-1 ],\n",
        "          [ 0 ],\n",
        "          [-1 ],\n",
        "          [ 0 ],\n",
        "          [-1 ],\n",
        "          [ 0 ],\n",
        "          [-1 ],\n",
        "          [ 0 ]], dtype=np.float64)\n",
        "\n",
        "Aux_M71 = np.array([\n",
        "          [0 , 1 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [1 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 1  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 1 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 1 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 1 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 , 1 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 1 , 0 ]], dtype=np.float64)\n",
        "\n",
        "Aux_M72 = np.array([\n",
        "          [1 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [-1 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 1 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 ,-1 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 1 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  ,-1 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 1 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 ,-1 , 0 ]], dtype=np.float64)\n",
        "\n",
        "Aux_M8  = np.array([\n",
        "          [0 , 1 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 ,-1 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 1  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 ,-1  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 1 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 ,-1 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 , 1 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 ,-1 ]], dtype=np.float64)\n",
        "Aux_Mb  = np.array([\n",
        "          [0 ,-1 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [1 , 0 , 0 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , -1  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 1 , 0  , 0 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 ,-1 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 1 , 0 , 0 , 0 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 0 ,-1 ],\n",
        "          [0 , 0 , 0 , 0  , 0 , 0 , 1 , 0 ]], dtype=np.float64)\n"
      ],
      "metadata": {
        "id": "Xq-ec_1uMR87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(U, theta, out_size, name='SpatialTransformer', **kwargs):\n",
        "    \"\"\"Spatial Transformer Layer\n",
        "\n",
        "    Implements a spatial transformer layer as described in [1]_.\n",
        "    Based on [2]_ and edited by David Dao for Tensorflow.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    U : float\n",
        "        The output of a convolutional net should have the\n",
        "        shape [num_batch, height, width, num_channels].\n",
        "    theta: float\n",
        "        The output of the\n",
        "        localisation network should be [num_batch, 6].\n",
        "    out_size: tuple of two ints\n",
        "        The size of the output of the network (height, width)\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    .. [1]  Spatial Transformer Networks\n",
        "            Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu\n",
        "            Submitted on 5 Jun 2015\n",
        "    .. [2]  https://github.com/skaae/transformer_network/blob/master/transformerlayer.py\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    To initialize the network to the identity transform init\n",
        "    ``theta`` to :\n",
        "        identity = np.array([[1., 0., 0.],\n",
        "                             [0., 1., 0.]])\n",
        "        identity = identity.flatten()\n",
        "        theta = tf.Variable(initial_value=identity)\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    scale_h= True  \n",
        "\n",
        "    def _repeat(x, n_repeats):\n",
        "        # Process \n",
        "        # dim2 = width\n",
        "        # dim1 = width*height\n",
        "        # v = tf.range(num_batch)*dim1\n",
        "        # print 'old v:', v # num_batch \n",
        "        # print 'new v:', tf.reshape(v, (-1, 1)) # widthx1\n",
        "        # n_repeats = 20 \n",
        "        # rep = tf.transpose(tf.expand_dims(tf.ones(shape=tf.stack([n_repeats, ])), 1), [1, 0]) # 1 x out_width*out_height \n",
        "        # print rep\n",
        "        # rep = tf.cast(rep, 'int32')\n",
        "        # v = tf.matmul(tf.reshape(v, (-1, 1)), rep) # v: num_batch x (out_width*out_height)\n",
        "        # print '--final v:\\n', v.eval() \n",
        "        # # v is the base. For parallel computing. \n",
        "        with tf.variable_scope('_repeat'):\n",
        "            rep = tf.transpose(\n",
        "                tf.expand_dims(tf.ones(shape=tf.stack([n_repeats, ])), 1), [1, 0])\n",
        "            rep = tf.cast(rep, 'int32')\n",
        "            x = tf.matmul(tf.reshape(x, (-1, 1)), rep)\n",
        "            return tf.reshape(x, [-1])\n",
        "\n",
        "    def _interpolate(im, x, y, out_size,scale_h):\n",
        "        with tf.variable_scope('_interpolate'):\n",
        "            # constants\n",
        "            num_batch = tf.shape(im)[0]\n",
        "            height = tf.shape(im)[1]\n",
        "            width = tf.shape(im)[2]\n",
        "            channels = tf.shape(im)[3]\n",
        "\n",
        "            x = tf.cast(x, 'float32')\n",
        "            y = tf.cast(y, 'float32')\n",
        "            height_f = tf.cast(height, 'float32')\n",
        "            width_f = tf.cast(width, 'float32')\n",
        "            out_height = out_size[0]\n",
        "            out_width = out_size[1]\n",
        "            zero = tf.zeros([], dtype='int32')\n",
        "            max_y = tf.cast(tf.shape(im)[1] - 1, 'int32')\n",
        "            max_x = tf.cast(tf.shape(im)[2] - 1, 'int32')\n",
        "\n",
        "            if scale_h:\n",
        "                # scale indices from [-1, 1] to [0, width/height]\n",
        "                print('--Inter- scale_h:', scale_h)\n",
        "                x = (x + 1.0)*(width_f) / 2.0\n",
        "                y = (y + 1.0)*(height_f) / 2.0\n",
        "\n",
        "            # do sampling\n",
        "            x0 = tf.cast(tf.floor(x), 'int32')\n",
        "            x1 = x0 + 1\n",
        "            y0 = tf.cast(tf.floor(y), 'int32')\n",
        "            y1 = y0 + 1\n",
        "\n",
        "            x0 = tf.clip_by_value(x0, zero, max_x)\n",
        "            x1 = tf.clip_by_value(x1, zero, max_x)\n",
        "            y0 = tf.clip_by_value(y0, zero, max_y)\n",
        "            y1 = tf.clip_by_value(y1, zero, max_y)\n",
        "            dim2 = width\n",
        "            dim1 = width*height\n",
        "            base = _repeat(tf.range(num_batch)*dim1, out_height*out_width)\n",
        "            base_y0 = base + y0*dim2\n",
        "            base_y1 = base + y1*dim2\n",
        "            idx_a = base_y0 + x0\n",
        "            idx_b = base_y1 + x0\n",
        "            idx_c = base_y0 + x1\n",
        "            idx_d = base_y1 + x1\n",
        "\n",
        "            # use indices to lookup pixels in the flat image and restore\n",
        "            # channels dim\n",
        "            im_flat = tf.reshape(im, tf.stack([-1, channels]))\n",
        "            im_flat = tf.cast(im_flat, 'float32')\n",
        "            Ia = tf.gather(im_flat, idx_a)\n",
        "            Ib = tf.gather(im_flat, idx_b)\n",
        "            Ic = tf.gather(im_flat, idx_c)\n",
        "            Id = tf.gather(im_flat, idx_d)\n",
        "\n",
        "            # and finally calculate interpolated values\n",
        "            x0_f = tf.cast(x0, 'float32')\n",
        "            x1_f = tf.cast(x1, 'float32')\n",
        "            y0_f = tf.cast(y0, 'float32')\n",
        "            y1_f = tf.cast(y1, 'float32')\n",
        "            wa = tf.expand_dims(((x1_f-x) * (y1_f-y)), 1)\n",
        "            wb = tf.expand_dims(((x1_f-x) * (y-y0_f)), 1)\n",
        "            wc = tf.expand_dims(((x-x0_f) * (y1_f-y)), 1)\n",
        "            wd = tf.expand_dims(((x-x0_f) * (y-y0_f)), 1)\n",
        "            output = tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])\n",
        "            return output\n",
        "\n",
        "    def _meshgrid(height, width, scale_h):\n",
        "        with tf.variable_scope('_meshgrid'):\n",
        "            # This should be equivalent to:\n",
        "            #  x_t, y_t = np.meshgrid(np.linspace(-1, 1, width),\n",
        "            #                         np.linspace(-1, 1, height))\n",
        "            #  ones = np.ones(np.prod(x_t.shape))\n",
        "            #  grid = np.vstack([x_t.flatten(), y_t.flatten(), ones])\n",
        "            #  Process: \n",
        "            # x1 = tf.ones(shape=tf.stack([height, 1])) # ones matrix of size height x 1 \n",
        "            # x2 =  tf.expand_dims(tf.linspace(0.0, tf.cast(width,'float32'), width), 1) # linespace(0,width,width) then expanded one more \n",
        "            #                                 # dimesion to width x 1 \n",
        "            # x3 = tf.transpose(x2, [1, 0])  # 1 x 1 x width \n",
        "            # x_t = tf.matmul(x1, x3)   # 1x height x width\n",
        "            # y_t = tf.matmul(tf.expand_dims(tf.linspace(0.0, tf.cast(height,'float32'), height), 1),\n",
        "            #             tf.ones(shape=tf.stack([1, width])))\n",
        "\n",
        "            # x_t_flat = tf.reshape(x_t, (1, -1)) # [linespace(0,width,width),  linespace(0,width,width) ....] \n",
        "            #  return: [-1, .. 0 ... , 1]\n",
        "            #          [-1, .. 0 ... , 1]\n",
        "            #          [1, .. 1 ... , 1]\n",
        "\n",
        "            if scale_h:\n",
        "                x_t = tf.matmul(tf.ones(shape=tf.stack([height, 1])),\n",
        "                                tf.transpose(tf.expand_dims(tf.linspace(-1.0, 1.0, width), 1), [1, 0]))\n",
        "                y_t = tf.matmul(tf.expand_dims(tf.linspace(-1.0, 1.0, height), 1),\n",
        "                                tf.ones(shape=tf.stack([1, width])))\n",
        "            else: \n",
        "                x_t = tf.matmul(tf.ones(shape=tf.stack([height, 1])),\n",
        "                            tf.transpose(tf.expand_dims(tf.linspace(0.0, tf.cast(width,'float32'), width), 1), [1, 0]))\n",
        "                y_t = tf.matmul(tf.expand_dims(tf.linspace(0.0, tf.cast(height,'float32'), height), 1),\n",
        "                            tf.ones(shape=tf.stack([1, width])))\n",
        "\n",
        "            x_t_flat = tf.reshape(x_t, (1, -1))\n",
        "            y_t_flat = tf.reshape(y_t, (1, -1))\n",
        "\n",
        "            ones = tf.ones_like(x_t_flat)\n",
        "            grid = tf.concat([x_t_flat, y_t_flat, ones], 0)\n",
        "            # sess = tf.get_default_session()\n",
        "            # print '--grid: \\n', grid.eval() # (session=sess.as_default())\n",
        "            return grid\n",
        "\n",
        "    def _transform(theta, input_dim, out_size, scale_h):\n",
        "        with tf.variable_scope('_transform'):\n",
        "            num_batch = tf.shape(input_dim)[0]\n",
        "            height = tf.shape(input_dim)[1]\n",
        "            width = tf.shape(input_dim)[2]\n",
        "            num_channels = tf.shape(input_dim)[3]\n",
        "            #  Changed \n",
        "            # theta = tf.reshape(theta, (-1, 2, 3))\n",
        "            theta = tf.reshape(theta, (-1, 3, 3))\n",
        "            theta = tf.cast(theta, 'float32')\n",
        "\n",
        "            #  Added: add two matrices M and B defined as follows in \n",
        "            # order to perform the equation: H x M x [xs...;ys...;1s...] + H x [width/2...;height/2...;0...]\n",
        "            theta_shape = theta.get_shape().as_list()\n",
        "            # initial\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # grid of (x_t, y_t, 1), eq (1) in ref [1]\n",
        "            height_f = tf.cast(height, 'float32')\n",
        "            width_f = tf.cast(width, 'float32')\n",
        "            out_height = out_size[0]\n",
        "            out_width = out_size[1]\n",
        "            grid = _meshgrid(out_height, out_width, scale_h)\n",
        "            grid = tf.expand_dims(grid, 0)\n",
        "            grid = tf.reshape(grid, [-1])\n",
        "            grid = tf.tile(grid, tf.stack([num_batch])) # stack num_batch grids \n",
        "            grid = tf.reshape(grid, tf.stack([num_batch, 3, -1]))\n",
        "\n",
        "            # Transform A x (x_t, y_t, 1)^T -> (x_s, y_s)\n",
        "            T_g = tf.matmul(theta, grid)\n",
        "            x_s = tf.slice(T_g, [0, 0, 0], [-1, 1, -1])\n",
        "            # Ty changed \n",
        "            # y_s = tf.slice(T_g, [0, 1, 0], [-1, 1, -1])\n",
        "            y_s = tf.slice(T_g, [0, 1, 0], [-1, 1, -1])\n",
        "            # Ty added \n",
        "            t_s = tf.slice(T_g, [0, 2, 0], [-1, 1, -1])\n",
        "            # The problem may be here as a general homo does not preserve the parallelism \n",
        "            # while an affine transformation preserves it. \n",
        "            t_s_flat = tf.reshape(t_s, [-1])\n",
        "\n",
        "            # Avoid zero division \n",
        "            zero = tf.constant(0, dtype=tf.float32)\n",
        "            one = tf.constant(1, dtype=tf.float32)\n",
        "\n",
        "\n",
        "            # smaller\n",
        "            small = tf.constant(1e-7, dtype=tf.float32)\n",
        "            smallers = 1e-6*(one - tf.cast(tf.greater_equal(tf.abs(t_s_flat), small),tf.float32)) \n",
        "             \n",
        "           \n",
        "            t_s_flat = t_s_flat + smallers \n",
        "            condition =  tf.reduce_sum(tf.cast(tf.greater(tf.abs(t_s_flat), small),tf.float32))\n",
        "            # Ty changed \n",
        "            # x_s_flat = tf.reshape(x_s, [-1])\n",
        "            # y_s_flat = tf.reshape(y_s, [-1])\n",
        "            x_s_flat = tf.reshape(x_s, [-1])/t_s_flat\n",
        "            y_s_flat = tf.reshape(y_s, [-1])/t_s_flat\n",
        "            \n",
        "\n",
        "            input_transformed =  _interpolate( input_dim, x_s_flat, y_s_flat,out_size,scale_h)\n",
        "\n",
        "            output = tf.reshape(\n",
        "                input_transformed, tf.stack([num_batch, out_height, out_width, num_channels]))\n",
        "            return output, condition\n",
        "\n",
        "    with tf.variable_scope(name):\n",
        "        output,condition = _transform(theta, U, out_size, scale_h)\n",
        "        return output, condition\n",
        "\n",
        "\n",
        "def batch_transformer(U, thetas, out_size, name='BatchSpatialTransformer'):\n",
        "    \"\"\"Batch Spatial Transformer Layer\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    U : float\n",
        "        tensor of inputs [num_batch,height,width,num_channels]\n",
        "    thetas : float\n",
        "        a set of transformations for each input [num_batch,num_transforms,6]\n",
        "    out_size : int\n",
        "        the size of the output [out_height,out_width]\n",
        "\n",
        "    Returns: float\n",
        "        Tensor of size [num_batch*num_transforms,out_height,out_width,num_channels]\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(name):\n",
        "        num_batch, num_transforms = map(int, thetas.get_shape().as_list()[:2])\n",
        "        indices = [[i]*num_transforms for i in xrange(num_batch)]\n",
        "        input_repeated = tf.gather(U, tf.reshape(indices, [-1]))\n",
        "        return transformer(input_repeated, thetas, out_size)\n"
      ],
      "metadata": {
        "id": "2__IS7sJMj16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPatchIndices(corners_a):\n",
        "    \"\"\"\n",
        "    For a given set of 4 corners, return it's indices inside the region as a mesh grid\n",
        "    -used in unsupervised model\n",
        "    \"\"\"\n",
        "    \n",
        "    patch_indices = []\n",
        "    for i in range(corners_a.shape[0]):\n",
        "        xmin,ymin = corners_a[i,0,0], corners_a[i,0,1]\n",
        "        xmax,ymax = corners_a[i,3,0], corners_a[i,3,1]\n",
        "#         print(xmin,ymin,xmax,ymax)\n",
        "        X, Y = np.mgrid[xmin:xmax, ymin:ymax]\n",
        "        patch_indices.append(np.dstack((Y,X))) \n",
        "    return np.array(patch_indices)\n",
        "\n",
        "def getCornersFromH4pt(corner1, H4pt):\n",
        "    corners1 = np.array(corner1.copy())\n",
        "    del_corners = H4pt.reshape(2,4).T\n",
        "    corners2 = corners1 + del_corners\n",
        "    return corners2\n",
        "\n",
        "def drawCorners(image, corners, color):\n",
        "\n",
        "    corners_ = np.array(corners.copy())\n",
        "    r = corners_[2,:].copy()\n",
        "    corners_[2,:] = corners_[3,:]\n",
        "    corners_[3,:] = r\n",
        "    corners_ = corners_.reshape(-1,1,2)\n",
        "#     print(corners_)\n",
        "    corners_ = corners_.astype(int)\n",
        "    image_corners = cv2.polylines(image.copy(),[corners_],True,color, 4)\n",
        "    return image_corners\n",
        "\n",
        "def getHfromH4pt(corners1, H4pt):\n",
        "#     print(\"H4pt is: \")\n",
        "#     print(H4pt.reshape(2,4).T)\n",
        "\n",
        "    del_corners = H4pt.reshape(2,4).T\n",
        "    \n",
        "    corners1 = np.array(corners1)\n",
        "#     print(\"corner1 is: \")\n",
        "#     print(corners1)\n",
        "\n",
        "    corners2 = corners1 + del_corners\n",
        "#     print(\"corner2 is: \")\n",
        "#     print(corners2)\n",
        "\n",
        "    H = cv2.getPerspectiveTransform(np.float32(corners1), np.float32(corners2))\n",
        "#     print(\"H is:\")\n",
        "#     print(H)\n",
        "    return H\n",
        "\n",
        "def warpImage(img, corners, H):\n",
        "    image = img.copy()\n",
        "    h, w, _= image.shape\n",
        "\n",
        "    corners_ = np.array(corners)\n",
        "    corners_ = corners_.reshape((-1,1,2))\n",
        "\n",
        "    image_transformed = cv2.warpPerspective(image, H, (w,h))\n",
        "    corner_transformed = cv2.perspectiveTransform(np.float32(corners_), H)\n",
        "    corner_transformed = corner_transformed.astype(int)\n",
        "    \n",
        "    return image_transformed, corner_transformed\n",
        "\n",
        "def Visualise_unsupervised(i, BasePath, SavePath, points_list, image_path):\n",
        "    Y_Pred = np.load(SavePath+\"unsupervised/H_Pred.npy\")\n",
        "\n",
        "    H4Y_true  = pd.read_csv(BasePath+\"/H_4pt.csv\", index_col =False)\n",
        "    H4Y_true = H4Y_true.to_numpy()\n",
        "\n",
        "    corners_a = points_list[i,:,:,0]\n",
        "\n",
        "    \n",
        "    imA = cv2.imread(image_path)\n",
        "\n",
        "    H_AB = getHfromH4pt(corners_a, H4Y_true[i])\n",
        "    imB, corners_b_cal = warpImage(imA, corners_a, H_AB)\n",
        "\n",
        "    imA_corners = drawCorners(imA, corners_a, (0,0,255))\n",
        "    imB_corners = drawCorners(imB, corners_b_cal, (0,0,255))\n",
        "\n",
        "    corners_a = corners_a.reshape((-1,1,2))\n",
        "    corners_b_pred = cv2.perspectiveTransform(np.float32(corners_a), Y_Pred[i])\n",
        "    corners_b_pred = corners_b_pred.astype(int)\n",
        "\n",
        "    imB_corners_pred = drawCorners(imB_corners, corners_b_pred, (0,255,255))\n",
        "    mce = np.mean(np.abs(corners_b_pred -  corners_b_cal)) #mean_corner_error \n",
        "    print(\"Mean corner Error for image at index \",i, \":  \",mce)\n",
        "\n",
        "    imB_corners_pred = cv2.putText(imB_corners_pred, \"MCE: \"+str(round(mce,3)),(150,230),cv2.FONT_HERSHEY_SIMPLEX,0.75,(255,0,0),2,cv2.LINE_AA)\n",
        "    return np.hstack((imA_corners,imB_corners_pred))\n"
      ],
      "metadata": {
        "id": "-OokJTH8KDOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def homography_model(img, image_size, batch_size):\n",
        "    x = tf.layers.conv2d(inputs=img, name='Conv2D1', padding='same',filters=64, kernel_size=[3,3], activation=None)\n",
        "    x = tf.layers.batch_normalization(x, name='BatchNorm1')\n",
        "    x = tf.nn.relu(x, name='Relu1')\n",
        "\n",
        "    x = tf.layers.conv2d(inputs=x, name='Conv2D2', padding='same',filters=64, kernel_size=[3,3], activation=None) \n",
        "    x = tf.layers.batch_normalization(x, name='BatchNorm2')\n",
        "    x = tf.nn.relu(x, name='Relu2')\n",
        "\n",
        "    x = tf.layers.max_pooling2d(inputs=x, pool_size=[2,2], strides=2)\n",
        "\n",
        "    x = tf.layers.conv2d(inputs=x, name='Conv2D3', padding='same',filters=64, kernel_size=[3,3], activation=None)\n",
        "    x = tf.layers.batch_normalization(x, name='BatchNorm3')\n",
        "    x = tf.nn.relu(x, name='Relu3')\n",
        "\n",
        "    x = tf.layers.conv2d(inputs=x, name='Conv2D4', padding='same',filters=64, kernel_size=[3,3], activation=None)\n",
        "    x = tf.layers.batch_normalization(x, name='BatchNorm4')\n",
        "    x = tf.nn.relu(x, name='Relu4')\n",
        "\n",
        "    x = tf.layers.max_pooling2d(inputs=x, pool_size=[2,2], strides=2)\n",
        "\n",
        "    x = tf.layers.conv2d(inputs=x, name='Conv2D5', padding='same',filters=128, kernel_size=[3,3], activation=None)\n",
        "    x = tf.layers.batch_normalization(x, name='BatchNorm5')\n",
        "    x = tf.nn.relu(x, name='Relu5')\n",
        "\n",
        "    x = tf.layers.conv2d(inputs=x, name='Conv2D6', padding='same',filters=128, kernel_size=[3,3], activation=None)\n",
        "    x = tf.layers.batch_normalization(x, name='BatchNorm6')\n",
        "    x = tf.nn.relu(x, name='Relu6')\n",
        "\n",
        "    x = tf.layers.max_pooling2d(inputs=x, pool_size=[2,2], strides=2)\n",
        "\n",
        "    x = tf.layers.conv2d(inputs=x, name='Conv2D7', padding='same',filters=128, kernel_size=[3,3], activation=None)\n",
        "    x = tf.layers.batch_normalization(x, name='BatchNorm7')\n",
        "    x = tf.nn.relu(x, name='Relu7')\n",
        "\n",
        "    x = tf.layers.conv2d(inputs=x, name='Conv2D8', padding='same',filters=128, kernel_size=[3,3], activation=None)\n",
        "    x = tf.layers.batch_normalization(x, name='BatchNorm8')\n",
        "    x = tf.nn.relu(x, name='Relu8')\n",
        "\n",
        "    #flattening layer\n",
        "    x = tf.contrib.layers.flatten(x)\n",
        "\n",
        "    #Fully-connected layers\n",
        "    x = tf.layers.dense(inputs=x, name='FC1',units=1024, activation=tf.nn.relu)\n",
        "    x = tf.layers.dropout(x,rate=0.5, training=True,name='Dropout')\n",
        "    x = tf.layers.batch_normalization(x, name='BatchNorm9')\n",
        "    H4 = tf.layers.dense(inputs=x, name='FCfinal',units=8, activation=None)\n",
        "\n",
        "    return H4\n",
        "\n",
        "\"\"\"\n",
        "TensorDLT model \n",
        "referred from :  https://github.com/tynguyen/unsupervisedDeepHomographyRAL2018/blob/master/code/utils/utils.py\n",
        "\"\"\" \n",
        "def TensorDLT(H4pt, C4A , MiniBatchSize):\n",
        "\n",
        "    pts_1_tile = tf.expand_dims(C4A, [2]) # BATCH_SIZE x 8 x 1\n",
        "\n",
        "    # Solve for H using DLT\n",
        "    pred_h4p_tile = tf.expand_dims(H4pt, [2]) # BATCH_SIZE x 8 x 1\n",
        "    # 4 points on the second image\n",
        "    pred_pts_2_tile = tf.add(pred_h4p_tile, pts_1_tile)\n",
        "\n",
        "\n",
        "    # Auxiliary tensors used to create Ax = b equation\n",
        "    M1_tile = tf.tile(tf.expand_dims(tf.constant(Aux_M1,tf.float32),[0]),[MiniBatchSize,1,1])\n",
        "    M2_tile = tf.tile(tf.expand_dims(tf.constant(Aux_M2,tf.float32),[0]),[MiniBatchSize,1,1])\n",
        "    M3_tile = tf.tile(tf.expand_dims(tf.constant(Aux_M3,tf.float32),[0]),[MiniBatchSize,1,1])\n",
        "    M4_tile = tf.tile(tf.expand_dims(tf.constant(Aux_M4,tf.float32),[0]),[MiniBatchSize,1,1])\n",
        "    M5_tile = tf.tile(tf.expand_dims(tf.constant(Aux_M5,tf.float32),[0]),[MiniBatchSize,1,1])\n",
        "    M6_tile = tf.tile(tf.expand_dims(tf.constant(Aux_M6,tf.float32),[0]),[MiniBatchSize,1,1])\n",
        "    M71_tile = tf.tile(tf.expand_dims(tf.constant(Aux_M71,tf.float32),[0]),[MiniBatchSize,1,1])\n",
        "    M72_tile = tf.tile(tf.expand_dims(tf.constant(Aux_M72,tf.float32),[0]),[MiniBatchSize,1,1])\n",
        "    M8_tile = tf.tile(tf.expand_dims(tf.constant(Aux_M8,tf.float32),[0]),[MiniBatchSize,1,1])\n",
        "    Mb_tile = tf.tile(tf.expand_dims(tf.constant(Aux_Mb,tf.float32),[0]),[MiniBatchSize,1,1])\n",
        "\n",
        "    # Form the equations Ax = b to compute H\n",
        "    # Form A matrix\n",
        "    A1 = tf.matmul(M1_tile, pts_1_tile) # Column 1\n",
        "    A2 = tf.matmul(M2_tile, pts_1_tile) # Column 2\n",
        "    A3 = M3_tile                   # Column 3\n",
        "    A4 = tf.matmul(M4_tile, pts_1_tile) # Column 4\n",
        "    A5 = tf.matmul(M5_tile, pts_1_tile) # Column 5\n",
        "    A6 = M6_tile                   # Column 6\n",
        "    A7 = tf.matmul(M71_tile, pred_pts_2_tile) *  tf.matmul(M72_tile, pts_1_tile)# Column 7\n",
        "    A8 = tf.matmul(M71_tile, pred_pts_2_tile) *  tf.matmul(M8_tile, pts_1_tile)# Column 8\n",
        "\n",
        "    A_mat = tf.transpose(tf.stack([tf.reshape(A1,[-1,8]),tf.reshape(A2,[-1,8]),\\\n",
        "                                    tf.reshape(A3,[-1,8]),tf.reshape(A4,[-1,8]),\\\n",
        "                                    tf.reshape(A5,[-1,8]),tf.reshape(A6,[-1,8]),\\\n",
        "                                    tf.reshape(A7,[-1,8]),tf.reshape(A8,[-1,8])],axis=1), perm=[0,2,1]) # BATCH_SIZE x 8 (A_i) x 8\n",
        "\n",
        "\n",
        "    print('--Shape of A_mat:', A_mat.get_shape().as_list())\n",
        "    # Form b matrix\n",
        "    b_mat = tf.matmul(Mb_tile, pred_pts_2_tile)\n",
        "    print('--shape of b:', b_mat.get_shape().as_list())\n",
        "\n",
        "    # Solve the Ax = b\n",
        "    H_8el = tf.matrix_solve(A_mat , b_mat)  # BATCH_SIZE x 8.\n",
        "    print('--shape of H_8el', H_8el)\n",
        "\n",
        "\n",
        "    # Add ones to the last cols to reconstruct H for computing reprojection error\n",
        "    h_ones = tf.ones([MiniBatchSize, 1, 1])\n",
        "    H_9el = tf.concat([H_8el,h_ones],1)\n",
        "    H_flat = tf.reshape(H_9el, [-1,9])\n",
        "    H_mat = tf.reshape(H_flat,[-1,3,3])   # BATCH_SIZE x 3 x 3\n",
        "\n",
        "    return H_mat\n",
        "\n",
        "def unsupervised_HomographyNet(patch_batches, c_a,  p_b, i_a, patch_indices, batch_size =50 ) :\n",
        "\n",
        "    batch_size,h,w,channels = i_a.get_shape().as_list()\n",
        "    H4_batches = homography_model(patch_batches, [128,128,1],50) \n",
        "    corners_a = tf.reshape(c_a,[batch_size,8]) \n",
        "    H_batches = TensorDLT(H4_batches , corners_a, batch_size)\n",
        "    # compute M\n",
        "    M = np.array([[w/2.0, 0., w/2.0],\n",
        "                    [0., h/2.0, h/2.0],\n",
        "                    [0., 0., 1.]]).astype(np.float32)\n",
        "\n",
        "    tensor_M = tf.constant(M, tf.float32)\n",
        "    tensor_M = tf.expand_dims(tensor_M, [0])\n",
        "    M_batches   = tf.tile(tensor_M, [batch_size, 1,1]) \n",
        "    #compute M_inv\n",
        "    M_inv = np.linalg.inv(M)\n",
        "    tensor_M_inv = tf.constant(M_inv, tf.float32)\n",
        "    tensor_M_inv = tf.expand_dims(tensor_M_inv, [0])\n",
        "    M_inv_batches   = tf.tile(tensor_M_inv, [batch_size,1,1]) \n",
        "    H_scaled = tf.matmul(tf.matmul(M_inv_batches, H_batches), M_batches)\n",
        "\n",
        "    warped_Ia, _ = transformer(i_a, H_scaled, (h,w))     \n",
        "\n",
        "    warped_Ia = tf.reshape(warped_Ia, [batch_size, h,w])\n",
        "    warped_Pa = tf.gather_nd(warped_Ia, patch_indices, name=None, batch_dims=1)\n",
        "\n",
        "    warped_Pa = tf.transpose(warped_Pa, perm = [0,2,1])\n",
        "\n",
        "    warped_Pa = tf.reshape(warped_Pa, [batch_size, 128, 128, 1])\n",
        "\n",
        "    return warped_Pa, p_b, H_batches"
      ],
      "metadata": {
        "id": "f27RPJH6J3Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_unsupervised(test_files_pa,test_files_pb,IA_files, points_list, shuffle = True):\n",
        "\n",
        "    patches_ab = []\n",
        "    ca = []\n",
        "    patches_b = []\n",
        "    I_A = []\n",
        "\n",
        "    for i in range(len(test_files_pa)):\n",
        "        patch_a = cv2.imread(test_files_pa[i], cv2.IMREAD_GRAYSCALE)\n",
        "        patch_b = cv2.imread(test_files_pb[i], cv2.IMREAD_GRAYSCALE)\n",
        "        image_a = cv2.imread(IA_files[i], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        patch_a = np.float32(patch_a)\n",
        "        patch_b = np.float32(patch_b) \n",
        "        image_a = np.float32(image_a)   \n",
        "\n",
        "        #combine images along depth\n",
        "        patch_ab = np.dstack((patch_a, patch_b))     \n",
        "        corner1 = points_list[i, :, :, 0]\n",
        "        \n",
        "        \n",
        "        patches_ab.append(patch_ab)\n",
        "        ca.append(corner1)\n",
        "        patches_b.append(patch_b.reshape(128, 128, 1))\n",
        "\n",
        "        I_A.append(image_a.reshape(image_a.shape[0], image_a.shape[1], 1))\n",
        "\n",
        "    patch_indices = getPatchIndices(np.array(ca))    \n",
        "    return np.array(patches_ab), np.array(ca), np.array(patches_b), np.array(I_A), patch_indices\n",
        "\n",
        "def Test_unsupervised(PatchPairsPH, CornerPH, Patch2PH, Image1PH,patchIndicesPH, ModelPath, test_files_pa, test_files_pb, image_files, pointsList, SavePath, NumTestSamples):\n",
        "    \"\"\"\n",
        "    Inputs: \n",
        "    ImgPH is the Input Image placeholder\n",
        "    ImageSize is the size of the image\n",
        "    ModelPath - Path to load trained model from\n",
        "    DataPath - Paths of all images where testing will be run on\n",
        "    LabelsPathPred - Path to save predictions\n",
        "    Outputs:\n",
        "    Predictions written to ./TxtFiles/PredOut.txt\n",
        "    \"\"\"\n",
        "    \n",
        "    if(not (os.path.isdir(SavePath))):\n",
        "        print(SavePath, \"  was not present, creating the folder...\")\n",
        "        os.makedirs(SavePath)\n",
        "\n",
        "    # Create the graph\n",
        "    # Predict output with forward pass, MiniBatchSize for Test is 1\n",
        "    _, _, H_batches = unsupervised_HomographyNet(PatchPairsPH, CornerPH, Patch2PH, Image1PH, patchIndicesPH, NumTestSamples)\n",
        "\n",
        "    # Setup Saver\n",
        "    # load session and run\n",
        "    Saver = tf.train.Saver()\n",
        "    with tf.Session() as sess:\n",
        "        Saver.restore(sess, ModelPath)\n",
        "        print('Number of parameters in this model are %d ' % np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()]))\n",
        "            \n",
        "        PatchPairsBatch, Corner1Batch, patch2Batch, Image1Batch, patchIndicesBatch = load_data_unsupervised(test_files_pa,test_files_pb,image_files, pointsList, shuffle = True)\n",
        "        FeedDict = {PatchPairsPH: PatchPairsBatch, CornerPH: Corner1Batch, Patch2PH: patch2Batch, Image1PH: Image1Batch, patchIndicesPH: patchIndicesBatch}            \n",
        "            \n",
        "        H_pred = sess.run(H_batches, FeedDict)\n",
        "        np.save(SavePath+'H_Pred.npy', H_pred)"
      ],
      "metadata": {
        "id": "vnmTyT1aJvcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9JqgLlGIQUA"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    tf.reset_default_graph()\n",
        "    # Parse Command Line arguments\n",
        "    # Parser = argparse.ArgumentParser()\n",
        "    # Parser.add_argument('--ModelPath', dest='ModelPath', default='../Checkpoints/unsupervised/99model.ckpt', help='Path to load latest model from, Default:ModelPath')\n",
        "    # Parser.add_argument('--CheckPointPath', dest='CheckPointPath', default= '../Checkpoints/unsupervised/', help='Path to load latest model from, Default:CheckPointPath')\n",
        "    # Parser.add_argument('--BasePath', dest='BasePath', default='../Data/Test_synthetic', help='Path to load images from, Default:BasePath')\n",
        "    # Parser.add_argument('--SavePath', dest='SavePath', default='./Results/', help='Path of labels file, Default: ./Results/')\n",
        "    # Parser.add_argument('--ModelType', default='Unsup', help='Model type, Supervised or Unsupervised? Choose from Sup and Unsup, Default:Unsup')\n",
        "    # base_dir = os.getcwd()\n",
        "    base_path = '/content/drive/MyDrive/Project_1'\n",
        "    # Args = Parser.parse_args()\n",
        "    ModelType = 'Unsup'\n",
        "    test_files_PA = glob.glob( base_path + '/S_val/P_A'+ '/*.jpg')\n",
        "    test_files_PB = glob.glob( base_path + '/S_val/P_B'+ '/*.jpg')\n",
        "    image_files = glob.glob( base_path + '/S_val/I_A'+ '/*.jpg')\n",
        "    NumTestSamples = len(test_files_PA)\n",
        "    if ModelType == 'Unsup':\n",
        "        ModelPath = '/content/drive/MyDrive/Project_1/unsupervised_checkpoints/74model.ckpt'\n",
        "        CheckPointPath = base_path + '/unsupervised_checkpoints/'\n",
        "        SavePath = base_path + '/unsupervised_test_results/'\n",
        "        \n",
        "        \n",
        "\n",
        "        print('The number of test samples is ' ,NumTestSamples)\n",
        "        pointsList = np.load(base_path + '/S_val/points_list.npy')\n",
        "\n",
        "        CornerPH = tf.placeholder(tf.float32, shape=(NumTestSamples, 4,2))\n",
        "        PatchPairsPH = tf.placeholder(tf.float32, shape=(NumTestSamples, 128, 128 ,2))\n",
        "        Patch2PH = tf.placeholder(tf.float32, shape=(NumTestSamples, 128, 128, 1))\n",
        "        Images1PH = tf.placeholder(tf.float32, shape=(NumTestSamples, 240, 320, 1))\n",
        "        patchIndicesPH = tf.placeholder(tf.int32, shape=(NumTestSamples, 128, 128 ,2))\n",
        "\n",
        "        Test_unsupervised(PatchPairsPH, CornerPH, Patch2PH, Images1PH,patchIndicesPH, ModelPath, test_files_PA, test_files_PB, image_files, pointsList, SavePath+\"unsupervised/\", NumTestSamples)\n",
        "         \n",
        "        # rand_i = np.random.randint(0,NumTestSamples-1, size=5)\n",
        "        im_list = [611, 395, 591, 678, 113, 509, 639]\n",
        "        for i in im_list:\n",
        "            image = image_files[i]\n",
        "            comparison = Visualise_unsupervised(i, base_path + '/S_val', SavePath, pointsList, image)\n",
        "            cv2.imwrite(SavePath+'/comparison'+ str(i)+'.png',comparison)        \n",
        "        print('Test results for unsupervised model are stored')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2J3Nps1Lj2z",
        "outputId": "760835fc-b0b7-4614-8ac6-d9fb9c19100c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of test samples is  1000\n",
            "WARNING:tensorflow:From <ipython-input-7-242bf89bab6a>:2: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-7-242bf89bab6a>:3: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:From <ipython-input-7-242bf89bab6a>:10: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-7-242bf89bab6a>:44: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-7-242bf89bab6a>:45: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "--Shape of A_mat: [1000, 8, 8]\n",
            "--shape of b: [1000, 8, 1]\n",
            "--shape of H_8el Tensor(\"MatrixSolve:0\", shape=(1000, 8, 1), dtype=float32)\n",
            "--Inter- scale_h: True\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/Project_1/unsupervised_checkpoints/74model.ckpt\n",
            "Number of parameters in this model are 34195848 \n",
            "Mean corner Error for image at index  611 :   22.375\n",
            "Mean corner Error for image at index  395 :   15.5\n",
            "Mean corner Error for image at index  591 :   35.5\n",
            "Mean corner Error for image at index  678 :   4.0\n",
            "Mean corner Error for image at index  113 :   60.625\n",
            "Mean corner Error for image at index  509 :   30.875\n",
            "Mean corner Error for image at index  639 :   31.625\n",
            "Test results for unsupervised model are stored\n"
          ]
        }
      ]
    }
  ]
}